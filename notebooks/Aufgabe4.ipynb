{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 4\n",
    "Trainieren Sie drei verschiedene Modelle, die in der Vorlesung behandelt wurden: ein `lineares Modell` (einfache lineare Regression, Ridge, Lasso), einen `Entscheidungsbaum` und ein `Ensemble-Modell` (Gradient Boosting oder Random Forest)\n",
    "1. Optimieren sie Hyperparameter der Modelle mittels Suche und Kreuzvalidierung. Überlegen Sie dazu zunächst (mit Hilfe der Vorlesungsunterlagen und der Dokumentation der Methoden in scikit-learn ), was für die jeweiligen Modelle Hyperparameter sind und für welche sich eine Optimierung ggf. lohnen könnte.\n",
    "2. WelchessinddiewichtigstenFeaturesfürdiejeweiligenModelle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der erforderlichen Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 1: Laden der Datensätze\n",
    "train_data_df = pd.read_csv('../data/raw/dmml1_train.csv')\n",
    "store_data_df = pd.read_csv('../data/raw/dmml1_stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_distance = store_data_df['CompetitionDistance'].median()\n",
    "store_data_df['CompetitionDistance'].fillna(median_distance, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 2: Ersetzen fehlender Werte in 'CompetitionDistance' und Merging der Datensätze\n",
    "median_distance = store_data_df['CompetitionDistance'].median()\n",
    "store_data_df['CompetitionDistance'].fillna(median_distance, inplace=True)\n",
    "\n",
    "merged_data = train_data_df.merge(store_data_df, on='Store ID', how='left')\n",
    "merged_data.drop(columns=['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 3: Anpassung der Datumsmerkmale und Generierung neuer Features\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "merged_data['Year'] = merged_data['Date'].dt.year\n",
    "merged_data['Month'] = merged_data['Date'].dt.month\n",
    "merged_data['Day'] = merged_data['Date'].dt.day\n",
    "merged_data['WeekOfYear'] = merged_data['Date'].dt.isocalendar().week\n",
    "merged_data['Weekend'] = np.where(merged_data['DayOfWeek'].isin([6, 7]), 1, 0)  # Samstag = 6, Sonntag = 7\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['Montag', 'Dienstag', 'Mittwoch', 'Donnerstag', 'Freitag', 'Samstag', 'Sonntag'], ordered=True)\n",
    "merged_data['Weekday'] = merged_data['Date'].dt.day_name(locale='de_DE').astype(cat_type)\n",
    "\n",
    "merged_data['Quarter'] = merged_data['Date'].dt.quarter\n",
    "merged_data['DayOfYear'] = merged_data['Date'].dt.dayofyear\n",
    "merged_data['DayOfMonth'] = merged_data['Date'].dt.day\n",
    "\n",
    "merged_data['Season'] = merged_data['Month'].apply(lambda month: (month%12 // 3 + 1))\n",
    "merged_data['Season'].replace(to_replace=[1,2,3,4], value=['Winter', 'Frühling','Sommer','Herbst'], inplace=True)\n",
    "\n",
    "# Entfernen der ursprünglichen Date-Spalte\n",
    "merged_data.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wladi/opt/anaconda3/envs/bv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Schritt 4: One-Hot-Encoding der kategorischen Variablen\n",
    "categorical_columns = ['StateHoliday', 'StoreType', 'Assortment', 'Season', 'Weekday']\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_columns = encoder.fit_transform(merged_data[categorical_columns])\n",
    "\n",
    "encoded_columns_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "merged_data_encoded = pd.concat([merged_data, encoded_columns_df], axis=1)\n",
    "merged_data_encoded.drop(categorical_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 5: Standardisierung der numerischen Spalten\n",
    "numerical_columns = [col for col in merged_data_encoded.columns \n",
    "                    if col not in ['Store ID', 'Open', 'Promo', 'SchoolHoliday', 'Promo2', 'Weekend'] \n",
    "                    and merged_data_encoded[col].nunique() > 2]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical = scaler.fit_transform(merged_data_encoded[numerical_columns])\n",
    "scaled_numerical_df = pd.DataFrame(scaled_numerical, columns=numerical_columns)\n",
    "for col in numerical_columns: \n",
    "    merged_data_encoded[col] = scaled_numerical_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 6: Vorbereitung der Daten für das lineare Regressionsmodell\n",
    "X = merged_data_encoded.drop(['Sales', 'Customers'], axis=1)\n",
    "y = merged_data_encoded['Sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 7: Initialisierung des linearen Regressionsmodells und RFE\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator)\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 8: Einsatz von GridSearchCV zur Ermittlung der optimalen Anzahl von Features\n",
    "param_grid = {\n",
    "    'n_features_to_select': list(range(1, n_features + 1, 1))\n",
    "}\n",
    "grid_search = GridSearchCV(selector, param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "# Training des GridSearchCV-Objekts\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 9: Auswahl und Training des Modells mit den besten Features\n",
    "best_n_features = grid_search.best_params_['n_features_to_select']\n",
    "selector = RFE(estimator, n_features_to_select=best_n_features)\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 10: Identifizieren der ausgewählten und weggelassenen Features\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "dropped_features = X_train.columns[~selector.support_]\n",
    "X_train_selected = X_train.loc[:, selector.support_]\n",
    "X_test_selected = X_test.loc[:, selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 11: Training des finalen linearen Regressionsmodells\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 12: Vorhersage und Berechnung des RMSE und R-Quadrat-Werts\n",
    "y_pred = final_model.predict(X_test_selected)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Optimale Anzahl von Features: {best_n_features} von {n_features}\")\n",
    "print(f\"Ausgewählte Features: {selected_features.tolist()}\")\n",
    "print(f\"Weggelassene Features: {dropped_features.tolist()}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) des finalen Modells: {rmse}\")\n",
    "print(f\"R-Quadrat (R²) des finalen Modells: {r_squared}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
